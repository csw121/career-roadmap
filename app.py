import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import platform
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import time

# ---------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="2025 ê°œë°œì ì»¤ë¦¬ì–´ ë¡œë“œë§µ & AI ë¶„ì„",
    page_icon="ğŸ§­",
    layout="wide"
)

# ---------------------------------------------------------
# 2. í•œê¸€ í°íŠ¸ ì„¤ì • (ê·¸ë˜í”„ ê¹¨ì§ ë°©ì§€)
# ---------------------------------------------------------
system_name = platform.system()
if system_name == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif system_name == 'Darwin': # Mac
    plt.rcParams['font.family'] = 'AppleGothic'
else: # Linux (Colab, Docker ë“±)
    plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

# ---------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ (ZIP íŒŒì¼ ì§€ì›)
# ---------------------------------------------------------
@st.cache_data
def load_data():
    try:
        # ê¹ƒí—ˆë¸Œ ìš©ëŸ‰ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ zip íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.
        # pandasëŠ” zip ë‚´ë¶€ì˜ csvë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ ì½ì–´ì¤ë‹ˆë‹¤.
        df = pd.read_csv('2025survey_results_public.csv')
        return df
    except Exception as e:
        return None

df = load_data()

# ---------------------------------------------------------
# 4. ì‚¬ì´ë“œë°”: ë°ì´í„° í™•ì¸ ë° ì§ë¬´ ì„ íƒ
# ---------------------------------------------------------
with st.sidebar:
    st.header("ğŸ“‚ ì„¤ì • ë° ì„ íƒ")

    if df is None:
        st.warning("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("2025survey_results_public.zip íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        uploaded_file = st.file_uploader("ë˜ëŠ” CSV/ZIP íŒŒì¼ì„ ì§ì ‘ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['csv', 'zip'])
        if uploaded_file:
            df = pd.read_csv(uploaded_file)
        else:
            st.stop()
    else:
        st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ({len(df):,}í–‰)")

    st.divider()
    st.subheader("ğŸ¯ ì§ë¬´ ì„ íƒ")

    if 'DevType' in df.columns:
        all_jobs = df['DevType'].dropna().astype(str).str.split(';').explode().str.strip().unique()
        all_jobs = sorted([job for job in all_jobs if job.lower() != 'nan'])
    else:
        st.error("'DevType' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    default_index = all_jobs.index('Developer, back-end') if 'Developer, back-end' in all_jobs else 0
    target_job = st.selectbox(
        "ë¶„ì„í•  ì§ë¬´ë¥¼ ê³ ë¥´ì„¸ìš”:",
        all_jobs,
        index=default_index
    )

    job_df = df[df['DevType'].astype(str).str.contains(target_job, case=False, na=False, regex=False)]
    respondents = len(job_df)

    st.markdown(f"--- \nğŸ‘¥ ë¶„ì„ ëŒ€ìƒ: **{respondents:,}ëª…**")

# ---------------------------------------------------------
# 5. ë©”ì¸ í™”ë©´ êµ¬ì„± (4ê°œì˜ íƒ­)
# ---------------------------------------------------------
st.title(f"ğŸ§­ [{target_job}] ì»¤ë¦¬ì–´ ì¸ì‚¬ì´íŠ¸ & ë¡œë“œë§µ")

# íƒ­ 4ê°œ ìƒì„± (ë§ˆì§€ë§‰ íƒ­ ì¶”ê°€ë¨)
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ê¸°ìˆ  íŠ¸ë Œë“œ", "ğŸ¤– AI ì¸ì‹", "ğŸ§  ML ì‹¬í™” ë¶„ì„", "ğŸ“ ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ…"])

# =========================================================
# [TAB 1] ê¸°ìˆ  ìŠ¤íƒ íŠ¸ë Œë“œ
# =========================================================
with tab1:
    st.markdown("### 1ï¸âƒ£ ê¸°ìˆ  ìŠ¤íƒ ë¡œë“œë§µ (í˜„ì¬ vs ë¯¸ë˜)")

    tech_cols = {
        'ğŸ’» ì–¸ì–´': ('LanguageHaveWorkedWith', 'LanguageWantToWorkWith'),
        'ğŸ—„ï¸ DB': ('DatabaseHaveWorkedWith', 'DatabaseWantToWorkWith'),
        'â˜ï¸ í”Œë«í¼': ('PlatformHaveWorkedWith', 'PlatformWantToWorkWith'),
        'ğŸ¤– AI ëª¨ë¸': ('AIModelsHaveWorkedWith', 'AIModelsWantToWorkWith')
    }

    def get_top_skills(data, col, n=7):
        if col not in data.columns: return pd.Series()
        return data[col].dropna().astype(str).str.split(';').explode().str.strip().value_counts().head(n)

    for i, (name, (curr, want)) in enumerate(tech_cols.items()):
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f"#### ğŸŸ¦ í˜„ì¬ (í•„ìˆ˜ ê¸°ìˆ ) - {name}")
            top_curr = get_top_skills(job_df, curr)
            if not top_curr.empty:
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.barplot(x=top_curr.values, y=top_curr.index, ax=ax, palette='Blues_r')
                ax.bar_label(ax.containers[0], fmt='%d', padding=3)
                st.pyplot(fig)
        with c2:
            st.markdown(f"#### ğŸŸ© ë¯¸ë˜ (ì„±ì¥ ê¸°ìˆ ) - {name}")
            top_want = get_top_skills(job_df, want)
            if not top_want.empty:
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.barplot(x=top_want.values, y=top_want.index, ax=ax, palette='Greens_r')
                ax.bar_label(ax.containers[0], fmt='%d', padding=3)
                st.pyplot(fig)
        st.divider()

# =========================================================
# [TAB 2] AI ìˆ˜ìš© íƒœë„
# =========================================================
with tab2:
    st.markdown("### 2ï¸âƒ£ ì´ ì§ë¬´ì˜ AI ìˆ˜ìš© íƒœë„")
    c1, c2 = st.columns(2)

    with c1:
        st.markdown("##### ğŸ˜¨ AIë¥¼ ìœ„í˜‘ìœ¼ë¡œ ëŠë¼ë‚˜ìš”?")
        if 'AIThreat' in job_df.columns:
            threat = job_df['AIThreat'].value_counts()
            if not threat.empty:
                fig, ax = plt.subplots(figsize=(5, 5))
                colors = {'Yes': '#ff9999', "I'm not sure": '#d3d3d3', 'No': '#99ff99'}
                pie_cols = [colors.get(x, '#abcdef') for x in threat.index]
                ax.pie(threat, labels=threat.index, autopct='%1.1f%%', startangle=90, colors=pie_cols)
                st.pyplot(fig)

    with c2:
        st.markdown("##### ğŸ˜¤ AI ë„êµ¬ì˜ ê°€ì¥ í° ë¶ˆë§Œì€?")
        if 'AIFrustration' in job_df.columns:
            frust = job_df['AIFrustration'].dropna().astype(str).value_counts().head(5)
            if not frust.empty:
                fig, ax = plt.subplots(figsize=(6, 4))
                sns.barplot(x=frust.values, y=frust.index, ax=ax, palette='Reds_r')
                st.pyplot(fig)

# =========================================================
# [TAB 3] ML ì‹¬í™” ë¶„ì„
# =========================================================
with tab3:
    st.markdown("### 3ï¸âƒ£ ë¨¸ì‹ ëŸ¬ë‹ ì‹¬í™” ë¶„ì„")

    st.subheader("ğŸ“Š ê°œë°œì ìœ í˜• êµ°ì§‘í™” (K-Means)")
    st.info("ğŸ’¡ ê²½ë ¥ê³¼ ì—°ë´‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œë°œìë“¤ì„ **3ê°€ì§€ ê·¸ë£¹**ìœ¼ë¡œ ìë™ ë¶„ë¥˜í•©ë‹ˆë‹¤.")

    ml_data = job_df[['YearsCode', 'ConvertedCompYearly']].dropna().copy()

    def clean_years(x):
        if x == 'Less than 1 year': return 0.5
        if x == 'More than 50 years': return 50
        try: return float(x)
        except: return 0

    ml_data['YearsCode_Num'] = ml_data['YearsCode'].apply(clean_years)
    ml_data = ml_data[ml_data['ConvertedCompYearly'] < 300000]

    if len(ml_data) > 30:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(ml_data[['YearsCode_Num', 'ConvertedCompYearly']])

        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
        ml_data['Cluster'] = kmeans.fit_predict(X_scaled)

        fig, ax = plt.subplots(figsize=(8, 5))
        sns.scatterplot(
            data=ml_data, x='YearsCode_Num', y='ConvertedCompYearly',
            hue='Cluster', palette='viridis', s=60, ax=ax
        )
        ax.set_title(f"[{target_job}] ê°œë°œì ê·¸ë£¹ ë¶„í¬")
        ax.set_xlabel("ê²½ë ¥ (ë…„)")
        ax.set_ylabel("ì—°ë´‰ (USD)")
        st.pyplot(fig)
    else:
        st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ êµ°ì§‘ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    st.subheader("ğŸ”— ê¸°ìˆ  ì¶”ì²œ (Association Analysis)")
    langs = job_df['LanguageHaveWorkedWith'].dropna().astype(str).str.split(';')
    all_langs = sorted(list(set([l for sublist in langs for l in sublist])))

    selected_lang = st.selectbox("ì–´ë–¤ ì–¸ì–´ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?", all_langs, index=0 if not all_langs else 0)

    related_skills = {}
    for user_skills in langs:
        if selected_lang in user_skills:
            for skill in user_skills:
                if skill != selected_lang:
                    related_skills[skill] = related_skills.get(skill, 0) + 1

    if related_skills:
        sorted_skills = sorted(related_skills.items(), key=lambda x: x[1], reverse=True)[:5]
        skill_names = [x[0] for x in sorted_skills]
        skill_counts = [x[1] for x in sorted_skills]

        fig, ax = plt.subplots(figsize=(8, 3))
        sns.barplot(x=skill_counts, y=skill_names, palette='magma')
        ax.set_title(f"'{selected_lang}' ì‚¬ìš©ìê°€ í•¨ê»˜ ì“°ëŠ” ê¸°ìˆ  Top 5")
        st.pyplot(fig)

# =========================================================
# [TAB 4] ì»¤ë¦¬ì–´ ì»¨ì„¤íŒ… (ìƒˆë¡œ ì¶”ê°€ëœ ê¸°ëŠ¥)
# =========================================================
with tab4:
    st.markdown("### ğŸ“ AI ì»¤ë¦¬ì–´ ë§ì¶¤ ì»¨ì„¤íŒ…")
    st.info("ğŸ’¡ ëª‡ ê°€ì§€ ì§ˆë¬¸ì— ë‹µí•˜ë©´, 2025ë…„ íŠ¸ë Œë“œì— ë§ëŠ” í•™ìŠµ ë¡œë“œë§µì„ ì„¤ê³„í•´ ë“œë¦½ë‹ˆë‹¤.")

    # --- ë°ì´í„°ë² ì´ìŠ¤ ---
    RECOMMENDATION_DB = {
        "interests": {
            "web": {"label": "ì›¹ ê°œë°œ (Full Stack)", "base_lang": "JavaScript / TypeScript", "desc": "ë¸Œë¼ìš°ì €ì™€ ì„œë²„ë¥¼ ì˜¤ê°€ëŠ” ë§ŒëŠ¥ ê°œë°œì"},
            "ai": {"label": "AI / ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤", "base_lang": "Python", "desc": "ë°ì´í„°ì—ì„œ ê°€ì¹˜ë¥¼ ì°½ì¶œí•˜ëŠ” ëª¨ë¸ ê°œë°œ"},
            "mobile": {"label": "ëª¨ë°”ì¼ ì•± ê°œë°œ", "base_lang": "Dart (Flutter) / Swift", "desc": "iOS/Android ì•±ì„ ë§Œë“œëŠ” í¬ë¦¬ì—ì´í„°"},
            "system": {"label": "ì‹œìŠ¤í…œ / ë°±ì—”ë“œ ìµœì í™”", "base_lang": "Go / Rust", "desc": "ê³ ì„±ëŠ¥ ì„œë²„ì™€ ì¸í”„ë¼ êµ¬ì¶•"}
        },
        "goals": {
            "employment": {"label": "ì·¨ì—… (ëŒ€ê¸°ì—…/ITê¸°ì—…)", "bonus": ["ì•Œê³ ë¦¬ì¦˜(Coding Test)", "CS ì§€ì‹", "ëŒ€ê·œëª¨ íŠ¸ë˜í”½ ì²˜ë¦¬"]},
            "startup": {"label": "ì°½ì—… / ì„œë¹„ìŠ¤ ëŸ°ì¹­", "bonus": ["ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘", "í´ë¼ìš°ë“œ ë°°í¬(AWS)", "ë§ˆì¼€íŒ… ê°ê°"]},
            "research": {"label": "ëŒ€í•™ì› / ì—°êµ¬", "bonus": ["ë…¼ë¬¸ ë¦¬ë”©", "ìˆ˜í•™/í†µê³„", "ì˜ì–´"]}
        }
    }

    # --- ì‚¬ìš©ì ì…ë ¥ ---
    col1, col2 = st.columns(2)
    with col1:
        user_interest_key = st.selectbox(
            "Q1. ê°€ì¥ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ëŠ”?",
            options=list(RECOMMENDATION_DB["interests"].keys()),
            format_func=lambda x: RECOMMENDATION_DB["interests"][x]["label"]
        )
    with col2:
        user_goal_key = st.selectbox(
            "Q2. í•™ìŠµì˜ ì£¼ëœ ëª©í‘œëŠ”?",
            options=list(RECOMMENDATION_DB["goals"].keys()),
            format_func=lambda x: RECOMMENDATION_DB["goals"][x]["label"]
        )

    user_level = st.radio("Q3. í˜„ì¬ ì½”ë”© ì‹¤ë ¥ì€?", ["ì…ë¬¸ (ì½”ë“œ ì²˜ìŒ ë´„)", "ì´ˆê¸‰ (ë¬¸ë²•ì€ ë—Œ)", "ì¤‘ê¸‰ (í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ)"], horizontal=True)

    # --- ë¶„ì„ ë²„íŠ¼ ---
    if st.button("ğŸš€ ë‚˜ë§Œì˜ ë¡œë“œë§µ ìƒì„±í•˜ê¸°", type="primary"):
        with st.spinner("ğŸ” AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            time.sleep(1.5)  # ë¡œë”© íš¨ê³¼

            # ì„ íƒëœ ë°ì´í„° ë§¤í•‘
            interest_data = RECOMMENDATION_DB["interests"][user_interest_key]
            goal_data = RECOMMENDATION_DB["goals"][user_goal_key]

            # ì¶”ì²œ ë¡œì§
            framework = ""
            ai_tools = ["GitHub Copilot"]

            if user_interest_key == 'web':
                framework = "Next.js + Supabase" if user_goal_key == 'startup' else "React + Spring Boot"
            elif user_interest_key == 'ai':
                framework = "PyTorch" if user_goal_key == 'research' else "TensorFlow + FastAPI"
                ai_tools.append("Hugging Face")
            elif user_interest_key == 'mobile':
                framework = "Flutter"
            else:
                framework = "Kubernetes + Docker"

            if user_goal_key == 'startup':
                ai_tools.extend(["Cursor IDE", "v0.dev"])
            elif user_goal_key == 'employment':
                ai_tools.append("LeetCode (AI Help)")

            if "ì…ë¬¸" in user_level:
                ai_tools.append("ChatGPT (íŠœí„°ë§ìš©)")

            # --- ê²°ê³¼ ì¶œë ¥ ---
            st.divider()
            st.success(f"ğŸ‰ **{interest_data['label']} ì „ë¬¸ê°€ ê³¼ì •**ì´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤!")

            r1, r2, r3 = st.columns(3)
            r1.metric("1ìˆœìœ„ ì–¸ì–´", interest_data['base_lang'])
            r2.metric("í•„ìˆ˜ í”„ë ˆì„ì›Œí¬", framework)
            r3.metric("ì¶”ì²œ AI ë„êµ¬", ai_tools[-1])

            st.markdown(f"""
            #### ğŸ“ ìƒì„¸ í•™ìŠµ ë¡œë“œë§µ
            1. **ê¸°ì´ˆ ë‹¤ì§€ê¸°**: {interest_data['base_lang'].split('/')[0]} ë¬¸ë²• ì™„ë²½ ì´í•´
            2. **ì‹¤ì „ ê¸°ìˆ **: {framework} ê³µì‹ ë¬¸ì„œë¡œ 'To-Do ë¦¬ìŠ¤íŠ¸' ë§Œë“¤ì–´ë³´ê¸°
            3. **ìŠ¤í™ ì—…**: {', '.join(goal_data['bonus'])} ì§‘ì¤‘ í•™ìŠµ
            4. **AI í™œìš©**: {', '.join(ai_tools)} ì„¤ì¹˜ ë° ì‚¬ìš©ë²• ìµíˆê¸°
            """)

            if user_goal_key == 'startup':
                st.caption("ğŸš€ íŒ: ì°½ì—…ì´ ëª©í‘œë¼ë©´ ì™„ë²½í•œ ì½”ë“œë³´ë‹¤ 'ì‹¤í–‰ë˜ëŠ” ì„œë¹„ìŠ¤'ë¥¼ ë¨¼ì € ë§Œë“œì„¸ìš”!")
            elif user_goal_key == 'research':
                st.caption("ğŸ“š íŒ: ìµœì‹  ë…¼ë¬¸(ArXiv)ì„ ìš”ì•½í•´ì£¼ëŠ” AI ì„œë¹„ìŠ¤ë¥¼ ì ê·¹ í™œìš©í•˜ì„¸ìš”.")

# ---------------------------------------------------------
# 6. ë§ˆë¬´ë¦¬ (í‘¸í„°)
# ---------------------------------------------------------
st.markdown("---")
st.caption("Â© 2025 Developer Roadmap Service | Data Source: Stack Overflow Survey")

